{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Notebook Introduction\n",
    "This notebook takes the synthetic example datasets and batches it into four significantly different subsets. A threshold\n",
    "of 10 weight percent of any given phase is used to batch the data, meaning that if a phase either enters or leaves the\n",
    "signal (with a threshold of 10 weight percent) the input data will be separated. The notebook then goes a step further\n",
    "by taking an exemplary INP topas file and editing it such that it will refine a number of basic parameters for a given\n",
    "batch of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Installation Instructions\n",
    "Run the following four cells when running for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!conda install pandas scipy scikit-learn numpy matplotlib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!conda install diffpy.utils -c diffpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "dir_path = os.getcwd()\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Confirm that you are in the diffpy.nmf_mapping folder before running the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# In order to use the code below, make sure to install the surrounding package first\n",
    "from diffpy.nmf_mapping import nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Register the directory containing the input files in xy, xye, or dat format. (not not mix and match, make sure it only contains the full batch of data to be processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "user_edited_input_file_directory_name = 'data/synthetic_r_vs_gr'\n",
    "\n",
    "input_directory = os.path.join(cwd, user_edited_input_file_directory_name)\n",
    "input_list, data_list = nmf.load_data(input_directory, xrd=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Repeatedly run the following cell with changes in the NMF_decomposition keyword (varName=varNum) arguments in order to get meaningful structural phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_components, df_phase_ratio_timeseries, df_reconstruction_error, df_explained_var_ratio = NMF.NMF_decomposition(input_list, pca_thresh=0.95)\n",
    "\n",
    "# When not using a PCA threshold, the explained variance variable will not exist. Remove this as one of the function outputs in this case, as shown in the comment below\n",
    "df_components, df_phase_ratio_timeseries, df_reconstruction_error = nmf.NMF_decomposition(input_list, improve_thresh=0.1)\n",
    "\n",
    "fig1 = nmf.component_plot(df_components, xrd=False)\n",
    "fig2 = nmf.component_ratio_plot(df_phase_ratio_timeseries)\n",
    "fig3 = nmf.reconstruction_error_plot(df_reconstruction_error)\n",
    "try:\n",
    "    fig4 = nmf.explained_variance_plot(df_explained_var_ratio)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Change \"line\" variable in following cell to define your threshold\n",
    "### base this on the NMF weights graph above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 0.1\n",
    "\n",
    "\n",
    "# Shift and concatenate DF columns\n",
    "df_phase_ratio_timeseries_transposed = df_phase_ratio_timeseries.T\n",
    "# initialize the shifted dataframe as the initial to get same dimensions\n",
    "shifted_ratio_df = df_phase_ratio_timeseries_transposed.copy()\n",
    "for i in range(len(df_phase_ratio_timeseries_transposed.columns)):\n",
    "    shifted_ratio_df.iloc[:,i] = df_phase_ratio_timeseries_transposed.iloc[:,i].shift(-1)\n",
    "# append the same dataframe shifted one up to the right of the initial dataframe\n",
    "conjoined_df = pd.concat([df_phase_ratio_timeseries_transposed, shifted_ratio_df], axis=1)\n",
    "# conjoined_df.head() # shows top 5 rows, but many more beneath\n",
    "\n",
    "# Finds where the data crosses the line\n",
    "num_cols = len(df_phase_ratio_timeseries_transposed.columns)\n",
    "conjoined_df['total_cross'] = False\n",
    "for i in range(len(df_phase_ratio_timeseries_transposed.columns)):\n",
    "    conjoined_df[f'cross_{i}'] = (\n",
    "        ((conjoined_df.iloc[:,i] >= line) & (conjoined_df.iloc[:,i + num_cols] < line)) |\n",
    "        ((conjoined_df.iloc[:,i + num_cols] > line) & (conjoined_df.iloc[:,i] <= line)) |\n",
    "        (conjoined_df.iloc[:,i] == line))\n",
    "    # adding is equivalend to or-ing the columns\n",
    "    conjoined_df['total_cross'] = conjoined_df['total_cross'] + conjoined_df[f'cross_{i}']\n",
    "file_separator_indexes = conjoined_df.index[conjoined_df['total_cross']].to_list()\n",
    "file_separator_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The following cell creates batch folders and separates the data into them based on the threshold from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shutil import copy, rmtree\n",
    "import re\n",
    "\n",
    "dir = Path(input_directory)\n",
    "data_list = list(dir.glob('*.xy'))\n",
    "if len(data_list) == 0:\n",
    "    data_list = list(dir.glob('*.xye'))\n",
    "if len(data_list) == 0:\n",
    "    data_list = list(dir.glob('*.dat'))\n",
    "if len(data_list) == 0:\n",
    "    data_list = list(dir.glob('*.gr'))\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys_file_name(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text.stem)]\n",
    "\n",
    "os.chdir(input_directory)\n",
    "data_list.sort(key=natural_keys_file_name)\n",
    "separator_count = 0\n",
    "file_batch = []\n",
    "for i, file in enumerate(data_list):\n",
    "    file_batch.append(file)\n",
    "    if separator_count == len(file_separator_indexes):\n",
    "        if i == (len(data_list)-1):\n",
    "            if len(file_batch) > 0:\n",
    "                new_dir_name = f'batch_{separator_count}'\n",
    "                if os.path.exists(new_dir_name):\n",
    "                    rmtree(new_dir_name)\n",
    "                os.mkdir(new_dir_name)\n",
    "                for file_to_copy in file_batch:\n",
    "                    copy(file_to_copy, os.path.join(os.getcwd(), new_dir_name))\n",
    "                file_batch = []\n",
    "            break\n",
    "    elif i == file_separator_indexes[separator_count]:\n",
    "        new_dir_name = f'batch_{separator_count}'\n",
    "        if os.path.exists(new_dir_name):\n",
    "            rmtree(new_dir_name)\n",
    "        os.mkdir(new_dir_name)\n",
    "        for file_to_copy in file_batch:\n",
    "            copy(file_to_copy, os.path.join(os.getcwd(), new_dir_name))\n",
    "        separator_count += 1\n",
    "        file_batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The following cell can be used to edit an INP file from a preliminary refinement on a batch to run a sequential refinement\n",
    "\n",
    "Note: This example is somewhat nonsensical as an XRD refinement is being performed on PDF data. Please ignore this discrepancy.\n",
    "\n",
    "### User inputs\n",
    "The user should edit the first three variables below in order to specify the INP filename, the batch directory name, and the output INP filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# End user should edit the following variables\n",
    "user_set_INP_filename = 'example.INP'\n",
    "User_set_batch_directory_name = 'batch_0'\n",
    "user_set_output_INP_filename = 'edited.INP'\n",
    "\n",
    "\n",
    "# No end-user editing required below this comment\n",
    "\n",
    "data_directory = os.path.join(cwd, 'data')\n",
    "INP_file_for_editing = os.path.join(data_directory, user_set_INP_filename)\n",
    "\n",
    "with open(INP_file_for_editing, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "print('='*50)\n",
    "print('\\tFile contents prior to editing')\n",
    "print('='*50)\n",
    "print(data)\n",
    "\n",
    "batch_directory = os.path.join(cwd, os.path.join('data/synthetic_r_vs_gr', User_set_batch_directory_name))\n",
    "\n",
    "phase_pattern = re.compile(r'(?<=\")(.*?)(?=\")')\n",
    "\n",
    "str_split_pattern = re.compile(r'(?<=str)(.*?)(?=str)|(?<=str)(.*?)$', flags=re.S)\n",
    "\n",
    "mvw_pattern = re.compile(r'(?<=MVW\\()(.*)(?=\\))')\n",
    "\n",
    "float_pattern = r'\\d+[.e][^,]+'\n",
    "\n",
    "float_pattern_with_space = r'\\s*\\d+[.e][^,]+'\n",
    "\n",
    "three_float_pattern = re.compile(fr'({float_pattern}),\\s*({float_pattern}),\\s*({float_pattern})')\n",
    "\n",
    "subsections_indices_string_tuple = [(i.span(), i.group()) for i in str_split_pattern.finditer(data)]\n",
    "\n",
    "mutable_file = list(data)\n",
    "\n",
    "parameter_tuple_list = []\n",
    "phase_list = []\n",
    "\n",
    "for indices, sub_string in reversed(subsections_indices_string_tuple):\n",
    "    # lists are mutable, strings are not\n",
    "    mutable_string = list(sub_string)\n",
    "    # the following finds the phase name and removes any dash\n",
    "    phase_name = re.search(phase_pattern, sub_string).group()\n",
    "    phase_name = phase_name.replace(\"-\", \"\")\n",
    "    phase_list.append(phase_name)\n",
    "    # switch out the mvw section\n",
    "    mvw_match = re.search(mvw_pattern, sub_string)\n",
    "    mutable_string[slice(*mvw_match.span())] = re.sub(three_float_pattern, \"MW_\" + phase_name + r' \\1,' + \"Vol_\" + phase_name + r' \\2,' + \"wf_\" + phase_name + r' \\3', mvw_match.group())\n",
    "\n",
    "    # turn the list back intro a string for upcoming re subs\n",
    "    newstring = ''.join(mutable_string)\n",
    "\n",
    "    newstring = re.sub(fr'scale\\s*@({float_pattern_with_space})', 'scale scale_' + phase_name + r' \\1', newstring)\n",
    "\n",
    "    a_string = None\n",
    "    b_string = None\n",
    "    c_string = None\n",
    "    al_string = None\n",
    "    be_string = None\n",
    "    ga_string = None\n",
    "\n",
    "    hex_pattern = fr'Hexagonal\\(@({float_pattern_with_space}),@\\s*({float_pattern})\\)'\n",
    "    tetr_pattern = fr'Tetragonal\\(@({float_pattern_with_space}),@\\s*({float_pattern})\\)'\n",
    "    trig_pattern = fr'Trigonal\\(@({float_pattern_with_space}),@\\s*({float_pattern})\\)'\n",
    "    cub_pattern = fr'Cubic\\(@({float_pattern_with_space})\\)'\n",
    "    a_pattern = fr'a\\s*@({float_pattern_with_space})'\n",
    "    b_pattern = fr'b\\s*@({float_pattern_with_space})'\n",
    "    c_pattern = fr'c\\s*@({float_pattern_with_space})'\n",
    "    al_pattern = fr'al\\s*@({float_pattern_with_space})'\n",
    "    be_pattern = fr'be\\s*@({float_pattern_with_space})'\n",
    "    ga_pattern = fr'ga\\s*@({float_pattern_with_space})'\n",
    "    if re.search(hex_pattern, newstring) is not None:\n",
    "        newstring = re.sub(hex_pattern, 'Hexagonal(' + 'a_' + phase_name + r' \\1,' + 'c_' + phase_name + r' \\2)', newstring)\n",
    "        a_string, c_string = 'a_' + phase_name, 'c_' + phase_name\n",
    "    elif re.search(tetr_pattern, newstring) is not None:\n",
    "        newstring = re.sub(tetr_pattern, 'Tetragonal(' + 'a_' + phase_name + r' \\1,' + 'c_' + phase_name + r' \\2)', newstring)\n",
    "        a_string, c_string = 'a_' + phase_name, 'c_' + phase_name\n",
    "    elif re.search(trig_pattern, newstring) is not None:\n",
    "        newstring = re.sub(trig_pattern, 'Trigonal(' + 'a_' + phase_name + r' \\1,' + 'c_' + phase_name + r' \\2)', newstring)\n",
    "        a_string, c_string = 'a_' + phase_name, 'c_' + phase_name\n",
    "    elif re.search(cub_pattern, newstring) is not None:\n",
    "        newstring = re.sub(cub_pattern, 'Cubic(' + 'a_' + phase_name + r' \\1)', newstring)\n",
    "        a_string = 'a_' + phase_name\n",
    "    else:\n",
    "        if re.search(a_pattern, newstring) is not None:\n",
    "            newstring = re.sub(a_pattern, 'a a_' + phase_name + r' \\1', newstring)\n",
    "            a_string = 'a_' + phase_name\n",
    "        if re.search(b_pattern, newstring) is not None:\n",
    "            newstring = re.sub(b_pattern, 'b b_' + phase_name + r' \\1', newstring)\n",
    "            b_string = 'b_' + phase_name\n",
    "        if re.search(c_pattern, newstring) is not None:\n",
    "            newstring = re.sub(c_pattern, 'c c_' + phase_name + r' \\1', newstring)\n",
    "            c_string = 'c_' + phase_name\n",
    "        if re.search(al_pattern, newstring) is not None:\n",
    "            newstring = re.sub(al_pattern, 'al al_' + phase_name + r' \\1', newstring)\n",
    "            al_string = 'al_' + phase_name\n",
    "        if re.search(be_pattern, newstring) is not None:\n",
    "            newstring = re.sub(be_pattern, 'be be_' + phase_name + r' \\1', newstring)\n",
    "            be_string = 'be_' + phase_name\n",
    "        if re.search(ga_pattern, newstring) is not None:\n",
    "            newstring = re.sub(ga_pattern, 'ga ga_' + phase_name + r' \\1', newstring)\n",
    "            ga_string = 'ga_' + phase_name\n",
    "\n",
    "    flag_tuple = (a_string, b_string, c_string, al_string, be_string, ga_string)\n",
    "\n",
    "    parameter_tuple_list.append(flag_tuple)\n",
    "\n",
    "    mutable_file[slice(*indices)] = newstring\n",
    "\n",
    "new_file = ''.join(mutable_file)\n",
    "\n",
    "# add the header without the list of filenames\n",
    "new_file = re.sub(r'(.*)(xdd )(\".*?\")',\n",
    "                   '#ifdef !topas_old_version \\n'\n",
    "                   'Backup_INP\\n'\n",
    "                   'out_file = Concat(String(INP_File), \".INP\");\\n'\n",
    "                   'num_runs 126\\n'\n",
    "                   '#list File_Name {\\n' +\n",
    "                   '}\\n' +\n",
    "                   'macro filename { File_Name(Run_Number) }\\n'\n",
    "                   '#endif\\n' +\n",
    "                   r'\\2' + 'filename',\n",
    "                   new_file, flags=re.S)\n",
    "\n",
    "file_list_section_match = re.search(r'\\{\\n\\}', new_file)\n",
    "\n",
    "prior_file_list_substring = new_file[:(file_list_section_match.start() + 2)]\n",
    "post_file_list_substring = new_file[(file_list_section_match.start() + 2):]\n",
    "\n",
    "# turn the list of files in this batch into a string\n",
    "dir = Path(batch_directory)\n",
    "batch_file_list = [str(path) for path in dir.glob('*.gr')]\n",
    "if len(batch_file_list)==0:\n",
    "    batch_file_list = [str(path) for path in dir.glob('*.xye')]\n",
    "newline_separated_filenames = \"\\n\".join(batch_file_list)\n",
    "\n",
    "# insert the string of filenames into the INP string\n",
    "new_file = prior_file_list_substring + newline_separated_filenames + post_file_list_substring\n",
    "\n",
    "# add the footer listing all of the variables to be output\n",
    "new_file += f'\\n\\t\\t#define write_out\\n' \\\n",
    "            f'out_file Concat(String(INP_File##Run_Number),\".Out\")\\n' \\\n",
    "            f'#ifdef write_out\\n' \\\n",
    "            f'out \"results.txt\" append\\n' \\\n",
    "            f'Out_String(filename)\\n' \\\n",
    "            f'Out(Get (r_wp), \" %11.5f\")\\n' \\\n",
    "            f'Out(Get (gof), \" %11.5f\")\\n'\n",
    "for phase in phase_list:\n",
    "    new_file += f'Out(MW_{phase}, \"%11.5f\")\\n' \\\n",
    "                f'Out(vol_{phase}, \"%11.5f\")\\n' \\\n",
    "                f'Out(wf_{phase}, \"%11.5f\")\\n' \\\n",
    "                f'Out(scale_{phase}, \"%11.5f\")\\n'\n",
    "\n",
    "for parameter_tuple in parameter_tuple_list:\n",
    "    for parameter in parameter_tuple:\n",
    "        if parameter is not None:\n",
    "            new_file += f'Out({parameter}, \"%11.5f\")\\n'\n",
    "print('='*50)\n",
    "print('\\tFile contents after editing')\n",
    "print('='*50)\n",
    "print(new_file)\n",
    "\n",
    "os.chdir(data_directory)\n",
    "\n",
    "with open(user_set_output_INP_filename, 'w') as f:\n",
    "    f.write(new_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (NMF_diffpy)",
   "language": "python",
   "name": "pycharm-35a25a26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
